{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import nltk\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import time\n",
    "\n",
    "from sklearn import preprocessing\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "\n",
    "from sklearn.naive_bayes import MultinomialNB\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.ensemble import AdaBoostClassifier\n",
    "\n",
    "from sklearn.metrics import f1_score\n",
    "from sklearn.metrics import accuracy_score\n",
    "from os import path"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "subdir = './datasets/twitter/'\n",
    "filename = 'bank_train.csv'\n",
    "df = pd.read_csv(path.join(subdir,filename))\n",
    "df_test = pd.read_csv(path.join(subdir, 'bank_test_etalon.csv'))\n",
    "sentiment_dict = pd.read_csv('./datasets/sentiment_dict.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from nltk.corpus import stopwords\n",
    "stop_words = stopwords.words('russian')\n",
    "#we can add stop words\n",
    "\n",
    "import pymorphy2\n",
    "def tokenize(text):\n",
    "    text = text.lower()\n",
    "    text_list = nltk.word_tokenize(text)\n",
    "    morph = pymorphy2.MorphAnalyzer()\n",
    "    text_list = [word for word in text_list if word[0] != '@' and len(word) > 1 and word.isalpha()]\n",
    "    text_list = [morph.parse(word)[0].normal_form for word in text_list]\n",
    "    return text_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#tf-idf vectorizer\n",
    "\n",
    "j = 0\n",
    "token_list = [i for i in df['text']]\n",
    "tfidf = TfidfVectorizer(tokenizer=tokenize, stop_words=stop_words)\n",
    "tfs = tfidf.fit_transform(token_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "X_train_all, y_train_all = None, None\n",
    "X_test_all, y_test_all = None, None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import ngram_vectorize\n",
    "token_list = [ngram_vectorize.get_ngrams(i,n=3,is_join=True) for i in df['text']]\n",
    "tfidf = TfidfVectorizer(stop_words=[])\n",
    "tfs = tfidf.fit_transform(token_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def df_filter(_df, _tfs, corporation):\n",
    "    x_arr = []\n",
    "    y_arr = []\n",
    "    for i in range(len(_df)):\n",
    "        label = _df[corporation][i]\n",
    "        if label == '0' or label == '-1' or label == '1' or label == 0.0 or label == -1.0 or label == 1.0:\n",
    "            x_arr.append(_tfs[i].toarray()[0])\n",
    "            y_arr.append(int(label))\n",
    "    X = np.array(x_arr)\n",
    "    y = np.array(y_arr)\n",
    "    print (len(X))\n",
    "    print (len(y))\n",
    "    return X, y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "562\n",
      "562\n",
      "372\n",
      "372\n",
      "278\n",
      "278\n",
      "929\n",
      "929\n",
      "2038\n",
      "2038\n",
      "82\n",
      "82\n",
      "1257\n",
      "1257\n"
     ]
    }
   ],
   "source": [
    "companies = ['alfabank', 'gazprom', 'raiffeisen', 'rshb', 'sberbank', 'uralsib', 'vtb']\n",
    "X_train, y_train = df_filter(_df=df, _tfs=tfs, corporation=companies[0])\n",
    "for companie in companies[1:]:\n",
    "    X_curr, y_curr = df_filter(_df=df, _tfs=tfs, corporation=companie)\n",
    "    X_train = np.append(X_train, X_curr, axis=0)\n",
    "    y_train = np.append(y_train, y_curr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "536\n",
      "536\n",
      "137\n",
      "137\n",
      "150\n",
      "150\n",
      "99\n",
      "99\n",
      "2833\n",
      "2833\n",
      "60\n",
      "60\n",
      "651\n",
      "651\n"
     ]
    }
   ],
   "source": [
    "companies = ['alfabank', 'gazprom', 'raiffeisen', 'rshb', 'sberbank', 'uralsib', 'vtb']\n",
    "X_test, y_test = df_filter(_df=df_test, _tfs=tfs, corporation=companies[0])\n",
    "for companie in companies[1:]:\n",
    "    X_curr, y_curr = df_filter(_df=df_test, _tfs=tfs, corporation=companie)\n",
    "    if len(X_curr) > 0:\n",
    "        X_test = np.append(X_test, X_curr, axis=0)\n",
    "        y_test = np.append(y_test, y_curr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(5518, 30598)\n",
      "(4466, 30598)\n"
     ]
    }
   ],
   "source": [
    "X_train_all = np.concatenate((X_train_all, X_train),axis=1)\n",
    "print (X_train_all.shape)\n",
    "X_test_all = np.concatenate((X_test_all, X_test), axis=1)\n",
    "print (X_test_all.shape)\n",
    "y_train_all = y_train\n",
    "y_test_all = y_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "14487"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(sentiment_dict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~\n",
      "SVM: \n",
      "fit time = 31m47sec\n",
      "predict time = 22m14sec\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.5/dist-packages/sklearn/metrics/classification.py:1113: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "f-macro: 0.2914040836904462\n",
      "f-micro: 0.7765338110165696\n"
     ]
    }
   ],
   "source": [
    "print ('~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~')\n",
    "print ('SVM: ')\n",
    "start_time = time.time()\n",
    "model = SVC()\n",
    "model.fit(X_train, y_train)\n",
    "t = int(time.time() - start_time)\n",
    "print ('fit time = {0}m{1}sec'.format(t // 60, t % 60))\n",
    "start_time = time.time()\n",
    "y_predict = model.predict(X_test)\n",
    "t = int(time.time() - start_time)\n",
    "print ('predict time = {0}m{1}sec'.format(t // 60, t % 60))\n",
    "print ('f-macro: {0}'.format(f1_score(y_test, y_predict, average = 'macro')))\n",
    "print ('f-micro: {0}'.format(f1_score(y_test, y_predict, average = 'micro')))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "strange f score - 0.45631578947368423\n"
     ]
    }
   ],
   "source": [
    "import my_score\n",
    "func= lambda x,y: my_score.f_macro(my_score.cound_diff(x,y))\n",
    "print ('strange f score - {0}'.format(func(y_predict, y_test)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[   0,  664,    0],\n",
       "       [   0, 3468,    0],\n",
       "       [   0,  334,    0]])"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.metrics import confusion_matrix\n",
    "confusion_matrix(y_test, y_predict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~\n",
      "Decision Tree: \n",
      "fit time = 0.1 6\n",
      "predict time = 0.0 0\n",
      "f-macro: 0.33241627485286734\n",
      "f-micro: 0.5853552859618717\n",
      "strange f score - 0.4235376068860566\n",
      "~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~\n",
      "AdaBoost DecisionTree max_depth = 2, n = 100: \n",
      "fit time = 3.2666666666666666 16\n",
      "predict time = 0.016666666666666666 1\n",
      "f-macro: 0.3298327295503713\n",
      "f-micro: 0.5899046793760832\n",
      "strange f score - 0.4228240132659454\n"
     ]
    }
   ],
   "source": [
    "print ('~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~')\n",
    "print ('Decision Tree: ')\n",
    "start_time = time.time()\n",
    "model = DecisionTreeClassifier()\n",
    "model.fit(X_train, y_train)\n",
    "t = int(time.time() - start_time)\n",
    "print ('fit time = {0} {1}'.format(t / 60, t % 60))\n",
    "start_time = time.time()\n",
    "y_predict = model.predict(X_test)\n",
    "t = int(time.time() - start_time)\n",
    "print ('predict time = {0} {1}'.format(t / 60, t % 60))\n",
    "print ('f-macro: {0}'.format(f1_score(y_test, y_predict, average = 'macro')))\n",
    "print ('f-micro: {0}'.format(f1_score(y_test, y_predict, average = 'micro')))\n",
    "print ('strange f score - {0}'.format(func(y_predict, y_test)))\n",
    "print ('~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~')\n",
    "print ('AdaBoost DecisionTree max_depth = 2, n = 100: ')\n",
    "start_time = time.time()\n",
    "model = AdaBoostClassifier(DecisionTreeClassifier(max_depth=5), n_estimators=100,\n",
    "learning_rate=1)\n",
    "model.fit(X_train, y_train)\n",
    "t = int(time.time() - start_time)\n",
    "print ('fit time = {0} {1}'.format(t / 60, t % 60))\n",
    "start_time = time.time()\n",
    "y_predict = model.predict(X_test)\n",
    "t = int(time.time() - start_time)\n",
    "print ('predict time = {0} {1}'.format(t / 60, t % 60))\n",
    "print ('f-macro: {0}'.format(f1_score(y_test, y_predict, average = 'macro')))\n",
    "print ('f-micro: {0}'.format(f1_score(y_test, y_predict, average = 'micro')))\n",
    "print ('strange f score - {0}'.format(func(y_predict, y_test)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#countVectorizer\n",
    "start_time = time.time()\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "vectorizer = CountVectorizer(min_df=1, tokenizer=tokenize, stop_words=stop_words)\n",
    "tfs4vec = vectorizer.fit_transform(token_list)\n",
    "t = int(time.time() - start_time)\n",
    "print ('TIME: {0}m {1}sec'.format(t / 60, t % 60))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "companies = ['raiffeisen']\n",
    "for companie in companies:\n",
    "    print('!!!!!!!!!!!!!!!!!')\n",
    "    print(companie)\n",
    "    print ('~~~~~~~~~~~~~~~~~')\n",
    "    \n",
    "    X, y = df_filter(_df = df, _tfs = tfs, corporation = companie)\n",
    "    X4, y4 = df_filter(_df = df, _tfs = tfs4vec, corporation = companie)\n",
    "    X_test, y_test = df_filter(_df = df_test, _tfs = tfs, corporation = companie)\n",
    "    X4_test, y4_test = df_filter(_df = df_test, _tfs = tfs4vec, corporation = companie)\n",
    "    \n",
    "    index = int((X.shape[0] + X_test.shape[0]) * 0.2)\n",
    "    if (index < X_test.shape[0]):\n",
    "        X = np.vstack((X, X_test[index:]))\n",
    "        X_test = X_test[:index]\n",
    "        y = np.concatenate((y,y_test[index:]))\n",
    "        y_test = y_test[:index]\n",
    "        X4 = np.vstack((X4, X4_test[index:]))\n",
    "        X4_test = X4_test[:index]\n",
    "        y4 = np.concatenate((y4,y4_test[index:]))\n",
    "        y4_test = y4_test[:index]\n",
    "    \n",
    "    print ('DATA SIZE: TRAIN = {0}, TEST= {1}'.format(X.shape[0], X_test.shape[0]))\n",
    "    print ('Naive Bayes: ')\n",
    "    start_time = time.time()\n",
    "    model = MultinomialNB()\n",
    "    model.fit(X, y)\n",
    "    t = int(time.time() - start_time)\n",
    "    print ('fit time = {0} {1}'.format(t / 60, t % 60))\n",
    "    start_time = time.time()\n",
    "    y_predict = model.predict(X_test)\n",
    "    print ('predict time = {0} {1}'.format(t / 60, t % 60))\n",
    "    print ('f-macro: {0}'.format(f1_score(y_test, y_predict, average = 'macro')))\n",
    "    print ('f-micro: {0}'.format(f1_score(y_test, y_predict, average = 'micro')))\n",
    "    t = int(time.time() - start_time)\n",
    "    print('~~~~~count vectorizer~~~~~~')\n",
    "    start_time = time.time()\n",
    "    model = MultinomialNB()\n",
    "    model.fit(X4, y4)\n",
    "    t = int(time.time() - start_time)\n",
    "    print ('fit time = {0} {1}'.format(t / 60, t % 60))\n",
    "    start_time = time.time()\n",
    "    y_predict = model.predict(X4_test)\n",
    "    t = int(time.time() - start_time)\n",
    "    print ('predict time = {0} {1}'.format(t / 60, t % 60)) \n",
    "    print ('f-macro: {0}'.format(f1_score(y4_test, y_predict, average = 'macro')))\n",
    "    print ('f-micro: {0}'.format(f1_score(y4_test, y_predict, average = 'micro')))\n",
    "    print ('~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~')\n",
    "    print ('SVM: ')\n",
    "    start_time = time.time()\n",
    "    model = SVC()\n",
    "    model.fit(X, y)\n",
    "    t = int(time.time() - start_time)\n",
    "    print ('fit time = {0} {1}'.format(t / 60, t % 60))\n",
    "    start_time = time.time()\n",
    "    y_predict = model.predict(X_test)\n",
    "    t = int(time.time() - start_time)\n",
    "    print ('predict time = {0} {1}'.format(t / 60, t % 60))\n",
    "    print ('f-macro: {0}'.format(f1_score(y_test, y_predict, average = 'macro')))\n",
    "    print ('f-micro: {0}'.format(f1_score(y_test, y_predict, average = 'micro')))\n",
    "    print('~~~~~count vectorizer~~~~~~')\n",
    "    start_time = time.time()\n",
    "    model = SVC()\n",
    "    model.fit(X4, y4)\n",
    "    t = int(time.time() - start_time)\n",
    "    print ('fit time = {0} {1}'.format(t / 60, t % 60))\n",
    "    start_time = time.time()\n",
    "    y_predict = model.predict(X4_test)\n",
    "    t = int(time.time() - start_time) \n",
    "    print ('predict time = {0} {1}'.format(t / 60, t % 60)) \n",
    "    print ('f-macro: {0}'.format(f1_score(y4_test, y_predict, average = 'macro')))\n",
    "    print ('f-micro: {0}'.format(f1_score(y4_test, y_predict, average = 'micro')))  \n",
    "    print ('~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~')\n",
    "    print ('SVM linear kernel: ')\n",
    "    start_time = time.time()\n",
    "    model = SVC(kernel = 'linear')\n",
    "    model.fit(X, y)\n",
    "    t = int(time.time() - start_time)\n",
    "    print ('fit time = {0} {1}'.format(t / 60, t % 60))\n",
    "    start_time = time.time()\n",
    "    y_predict = model.predict(X_test)\n",
    "    t = int(time.time() - start_time)\n",
    "    print ('predict time = {0} {1}'.format(t / 60, t % 60))\n",
    "    print ('f-macro: {0}'.format(f1_score(y_test, y_predict, average = 'macro')))\n",
    "    print ('f-micro: {0}'.format(f1_score(y_test, y_predict, average = 'micro')))\n",
    "    print('~~~~~count vectorizer~~~~~~')\n",
    "    start_time = time.time()\n",
    "    model = SVC(kernel = 'linear')\n",
    "    model.fit(X4, y4)\n",
    "    t = int(time.time() - start_time)\n",
    "    print ('fit time = {0} {1}'.format(t / 60, t % 60))\n",
    "    start_time = time.time()\n",
    "    y_predict = model.predict(X4_test)\n",
    "    t = int(time.time() - start_time) \n",
    "    print ('predict time = {0} {1}'.format(t / 60, t % 60)) \n",
    "    print ('f-macro: {0}'.format(f1_score(y4_test, y_predict, average = 'macro')))\n",
    "    print ('f-micro: {0}'.format(f1_score(y4_test, y_predict, average = 'micro')))\n",
    "    print ('~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~')\n",
    "    print ('kNN 10: ')\n",
    "    start_time = time.time()\n",
    "    model = KNeighborsClassifier(n_neighbors=10)\n",
    "    model.fit(X, y)\n",
    "    t = int(time.time() - start_time)\n",
    "    print ('fit time = {0} {1}'.format(t / 60, t % 60))\n",
    "    start_time = time.time()\n",
    "    y_predict = model.predict(X_test)\n",
    "    t = int(time.time() - start_time)\n",
    "    print ('predict time = {0} {1}'.format(t / 60, t % 60))\n",
    "    print ('f-macro: {0}'.format(f1_score(y_test, y_predict, average = 'macro')))\n",
    "    print ('f-micro: {0}'.format(f1_score(y_test, y_predict, average = 'micro')))\n",
    "    print('~~~~~count vectorizer~~~~~~')\n",
    "    start_time = time.time()\n",
    "    model =  KNeighborsClassifier(n_neighbors=10)\n",
    "    model.fit(X4, y4)\n",
    "    t = int(time.time() - start_time)\n",
    "    print ('fit time = {0} {1}'.format(t / 60, t % 60))\n",
    "    start_time = time.time()\n",
    "    y_predict = model.predict(X4_test)\n",
    "    t = int(time.time() - start_time) \n",
    "    print ('predict time = {0} {1}'.format(t / 60, t % 60)) \n",
    "    print ('f-macro: {0}'.format(f1_score(y4_test, y_predict, average = 'macro')))\n",
    "    print ('f-micro: {0}'.format(f1_score(y4_test, y_predict, average = 'micro')))\n",
    "    print ('~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~')\n",
    "    print ('kNN 5: ')\n",
    "    start_time = time.time()\n",
    "    model = KNeighborsClassifier(n_neighbors=5)\n",
    "    model.fit(X, y)\n",
    "    t = int(time.time() - start_time)\n",
    "    print ('fit time = {0} {1}'.format(t / 60, t % 60))\n",
    "    start_time = time.time()\n",
    "    y_predict = model.predict(X_test)\n",
    "    t = int(time.time() - start_time)\n",
    "    print ('predict time = {0} {1}'.format(t / 60, t % 60))\n",
    "    print ('f-macro: {0}'.format(f1_score(y_test, y_predict, average = 'macro')))\n",
    "    print ('f-micro: {0}'.format(f1_score(y_test, y_predict, average = 'micro')))\n",
    "    print('~~~~~count vectorizer~~~~~~')\n",
    "    start_time = time.time()\n",
    "    model =  KNeighborsClassifier(n_neighbors=5)\n",
    "    model.fit(X4, y4)\n",
    "    t = int(time.time() - start_time)\n",
    "    print ('fit time = {0} {1}'.format(t / 60, t % 60))\n",
    "    start_time = time.time()\n",
    "    y_predict = model.predict(X4_test)\n",
    "    t = int(time.time() - start_time) \n",
    "    print ('predict time = {0} {1}'.format(t / 60, t % 60)) \n",
    "    print ('f-macro: {0}'.format(f1_score(y4_test, y_predict, average = 'macro')))\n",
    "    print ('f-micro: {0}'.format(f1_score(y4_test, y_predict, average = 'micro')))\n",
    "    print ('~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~')\n",
    "    print ('kNN 3: ')\n",
    "    start_time = time.time()\n",
    "    model = KNeighborsClassifier(n_neighbors=3)\n",
    "    model.fit(X, y)\n",
    "    t = int(time.time() - start_time)\n",
    "    print ('fit time = {0} {1}'.format(t / 60, t % 60))\n",
    "    start_time = time.time()\n",
    "    y_predict = model.predict(X_test)\n",
    "    t = int(time.time() - start_time)\n",
    "    print ('predict time = {0} {1}'.format(t / 60, t % 60))\n",
    "    print ('f-macro: {0}'.format(f1_score(y_test, y_predict, average = 'macro')))\n",
    "    print ('f-micro: {0}'.format(f1_score(y_test, y_predict, average = 'micro')))\n",
    "    print('~~~~~count vectorizer~~~~~~')\n",
    "    start_time = time.time()\n",
    "    model =  KNeighborsClassifier(n_neighbors=3)\n",
    "    model.fit(X4, y4)\n",
    "    t = int(time.time() - start_time)\n",
    "    print ('fit time = {0} {1}'.format(t / 60, t % 60))\n",
    "    start_time = time.time()\n",
    "    y_predict = model.predict(X4_test)\n",
    "    t = int(time.time() - start_time) \n",
    "    print ('predict time = {0} {1}'.format(t / 60, t % 60)) \n",
    "    print ('f-macro: {0}'.format(f1_score(y4_test, y_predict, average = 'macro')))\n",
    "    print ('f-micro: {0}'.format(f1_score(y4_test, y_predict, average = 'micro')))\n",
    "    print ('~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~')\n",
    "    print ('kNN 7: ')\n",
    "    start_time = time.time()\n",
    "    model = KNeighborsClassifier(n_neighbors=7)\n",
    "    model.fit(X, y)\n",
    "    t = int(time.time() - start_time)\n",
    "    print ('fit time = {0} {1}'.format(t / 60, t % 60))\n",
    "    start_time = time.time()\n",
    "    y_predict = model.predict(X_test)\n",
    "    t = int(time.time() - start_time)\n",
    "    print ('predict time = {0} {1}'.format(t / 60, t % 60))\n",
    "    print ('f-macro: {0}'.format(f1_score(y_test, y_predict, average = 'macro')))\n",
    "    print ('f-micro: {0}'.format(f1_score(y_test, y_predict, average = 'micro')))\n",
    "    print('~~~~~count vectorizer~~~~~~')\n",
    "    start_time = time.time()\n",
    "    model =  KNeighborsClassifier(n_neighbors=7)\n",
    "    model.fit(X4, y4)\n",
    "    t = int(time.time() - start_time)\n",
    "    print ('fit time = {0} {1}'.format(t / 60, t % 60))\n",
    "    start_time = time.time()\n",
    "    y_predict = model.predict(X4_test)\n",
    "    t = int(time.time() - start_time) \n",
    "    print ('predict time = {0} {1}'.format(t / 60, t % 60)) \n",
    "    print ('f-macro: {0}'.format(f1_score(y4_test, y_predict, average = 'macro')))\n",
    "    print ('f-micro: {0}'.format(f1_score(y4_test, y_predict, average = 'micro')))\n",
    "    print ('~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~')\n",
    "    print ('kNN 30: ')\n",
    "    start_time = time.time()\n",
    "    model = KNeighborsClassifier(n_neighbors=30)\n",
    "    model.fit(X, y)\n",
    "    t = int(time.time() - start_time)\n",
    "    print ('fit time = {0} {1}'.format(t / 60, t % 60))\n",
    "    start_time = time.time()\n",
    "    y_predict = model.predict(X_test)\n",
    "    t = int(time.time() - start_time)\n",
    "    print ('predict time = {0} {1}'.format(t / 60, t % 60))\n",
    "    print ('f-macro: {0}'.format(f1_score(y_test, y_predict, average = 'macro')))\n",
    "    print ('f-micro: {0}'.format(f1_score(y_test, y_predict, average = 'micro')))\n",
    "    print('~~~~~count vectorizer~~~~~~')\n",
    "    start_time = time.time()\n",
    "    model =  KNeighborsClassifier(n_neighbors=30)\n",
    "    model.fit(X4, y4)\n",
    "    t = int(time.time() - start_time)\n",
    "    print ('fit time = {0} {1}'.format(t / 60, t % 60))\n",
    "    start_time = time.time()\n",
    "    y_predict = model.predict(X4_test)\n",
    "    t = int(time.time() - start_time) \n",
    "    print ('predict time = {0} {1}'.format(t / 60, t % 60)) \n",
    "    print ('f-macro: {0}'.format(f1_score(y4_test, y_predict, average = 'macro')))\n",
    "    print ('f-micro: {0}'.format(f1_score(y4_test, y_predict, average = 'micro')))\n",
    "    print ('~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~')\n",
    "    print ('Decision Tree: ')\n",
    "    start_time = time.time()\n",
    "    model = DecisionTreeClassifier()\n",
    "    model.fit(X, y)\n",
    "    t = int(time.time() - start_time)\n",
    "    print ('fit time = {0} {1}'.format(t / 60, t % 60))\n",
    "    start_time = time.time()\n",
    "    y_predict = model.predict(X_test)\n",
    "    t = int(time.time() - start_time)\n",
    "    print ('predict time = {0} {1}'.format(t / 60, t % 60))\n",
    "    print ('f-macro: {0}'.format(f1_score(y_test, y_predict, average = 'macro')))\n",
    "    print ('f-micro: {0}'.format(f1_score(y_test, y_predict, average = 'micro')))\n",
    "    print('~~~~~count vectorizer~~~~~~')\n",
    "    start_time = time.time()\n",
    "    model =  DecisionTreeClassifier()\n",
    "    model.fit(X4, y4)\n",
    "    t = int(time.time() - start_time)\n",
    "    print ('fit time = {0} {1}'.format(t / 60, t % 60))\n",
    "    start_time = time.time()\n",
    "    y_predict = model.predict(X4_test)\n",
    "    t = int(time.time() - start_time) \n",
    "    print ('predict time = {0} {1}'.format(t / 60, t % 60)) \n",
    "    print ('f-macro: {0}'.format(f1_score(y4_test, y_predict, average = 'macro')))\n",
    "    print ('f-micro: {0}'.format(f1_score(y4_test, y_predict, average = 'micro')))\n",
    "    print ('~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~')\n",
    "    print ('Decision Tree max depth = 5: ')\n",
    "    start_time = time.time()\n",
    "    model = DecisionTreeClassifier(max_depth = 5)\n",
    "    model.fit(X, y)\n",
    "    t = int(time.time() - start_time)\n",
    "    print ('fit time = {0} {1}'.format(t / 60, t % 60))\n",
    "    start_time = time.time()\n",
    "    y_predict = model.predict(X_test)\n",
    "    t = int(time.time() - start_time)\n",
    "    print ('predict time = {0} {1}'.format(t / 60, t % 60))\n",
    "    print ('f-macro: {0}'.format(f1_score(y_test, y_predict, average = 'macro')))\n",
    "    print ('f-micro: {0}'.format(f1_score(y_test, y_predict, average = 'micro')))\n",
    "    print('~~~~~count vectorizer~~~~~~')\n",
    "    start_time = time.time()\n",
    "    model =  DecisionTreeClassifier(max_depth = 5)\n",
    "    model.fit(X4, y4)\n",
    "    t = int(time.time() - start_time)\n",
    "    print ('fit time = {0} {1}'.format(t / 60, t % 60))\n",
    "    start_time = time.time()\n",
    "    y_predict = model.predict(X4_test)\n",
    "    t = int(time.time() - start_time) \n",
    "    print ('predict time = {0} {1}'.format(t / 60, t % 60)) \n",
    "    print ('f-macro: {0}'.format(f1_score(y4_test, y_predict, average = 'macro')))\n",
    "    print ('f-micro: {0}'.format(f1_score(y4_test, y_predict, average = 'micro')))\n",
    "    print ('~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~')\n",
    "    print ('AdaBoost DecisionTree max_depth = 2, n = 100: ')\n",
    "    start_time = time.time()\n",
    "    model = AdaBoostClassifier(DecisionTreeClassifier(max_depth=2), n_estimators=100,\n",
    "    learning_rate=1)\n",
    "    model.fit(X, y)\n",
    "    t = int(time.time() - start_time)\n",
    "    print ('fit time = {0} {1}'.format(t / 60, t % 60))\n",
    "    start_time = time.time()\n",
    "    y_predict = model.predict(X_test)\n",
    "    t = int(time.time() - start_time)\n",
    "    print ('predict time = {0} {1}'.format(t / 60, t % 60))\n",
    "    print ('f-macro: {0}'.format(f1_score(y_test, y_predict, average = 'macro')))\n",
    "    print ('f-micro: {0}'.format(f1_score(y_test, y_predict, average = 'micro')))\n",
    "    print('~~~~~count vectorizer~~~~~~')\n",
    "    start_time = time.time()\n",
    "    model =  AdaBoostClassifier(DecisionTreeClassifier(max_depth=2), n_estimators=100,\n",
    "    learning_rate=1)\n",
    "    model.fit(X4, y4)\n",
    "    t = int(time.time() - start_time)\n",
    "    print ('fit time = {0} {1}'.format(t / 60, t % 60))\n",
    "    start_time = time.time()\n",
    "    y_predict = model.predict(X4_test)\n",
    "    t = int(time.time() - start_time) \n",
    "    print ('predict time = {0} {1}'.format(t / 60, t % 60)) \n",
    "    print ('f-macro: {0}'.format(f1_score(y4_test, y_predict, average = 'macro')))\n",
    "    print ('f-micro: {0}'.format(f1_score(y4_test, y_predict, average = 'micro')))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
